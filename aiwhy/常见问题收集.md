# interestingresources
collect something interesting

you can go to github trends to explore new interesting things on github

new pull request is welcome

介绍一下逻辑回归，这里问得非常细致。包括他的训练过程，他是怎么得到权重，怎么更新权重，为什么要选择梯度方向进行优化，从数学角度来说一下（有必要用自己的语言去整理和写一下代码）

l1和l2正则化，区别与应用场景

用数学语言解释梯度下降

knn与k-means的区别

分类指标

滤波知识：均值滤波、中值滤波、维纳滤波

问题：python数据类型中，不可变的有哪些，可变的有哪些
答：不可变的是元组，可变的是字典、列表

偏差、方差区别

模型比较复杂的时候，偏差和方差的变化：偏差变小，方差变大

1*1 卷积的作用：（我没有答出来） 面试官 补充到：主要是起到降维或者是获取到更多特征的作用

数据不平衡的时候的处理方法，比如说正样本多 https://blog.csdn.net/shenxiaoming77/article/details/72616333
1采样 上采样和下采样 上采样是把小众类复制多份，下采样是从大众类中剔除一些样本，或者说只从大众类中选取部分样本
2数据合成 用已有样本生成更多样本，这类方法在小数据场景下有很多成功案例
3加权 boosting

数据增强的方法

模型过拟合了怎么办：数据增强、修改模型、L1和L2正则化

KNN和K-means

L1和L2正则化的区别 L1趋向于产生少量的特征，其他特征为0，因为最优参数很大概率出现在坐标轴上，导致某一维的权重为0，产生稀疏矩阵。 L2趋向于选择更多的特征，这些特征会接近于0，最优的参数值很小概率出现在坐标轴上，每一维的参数不会是0.当最小化||w||时，就会使每一项趋向于0

1、ROC,AUC（没答出来）

2、gdbt、xgboost、随机森林有什么区别（没答出来）

3、激活函数

4、过拟合、欠拟合

笔试结束了之后，突如其来的面试 就赶着问，最后面试官给我的建议是让我找一个具体的点，去kaggle上动手做实验。 然后自己要有一个非常熟悉的点，比如就算是简单的LR，优缺点、应用场景也要弄得很清楚。

虚函数的作用：函数的作用是允许在派生类中重新定义与基类同名的函数，并且可以通过基类指针或引用来访问基类和派生类中的同名函数

栈和函数调用的关系

栈和队列的区别

介绍熟悉的机器学习算法，并推导svm

介绍gan

介绍堆排序

聊项目以及拓展

了解过deapfake吗

梯度消失的原因以及解决方法

为什么使用sigmoid激活函数会导致梯度消失

面试套路大概归结为下面流程：
1、先做一个简短的自我介绍
答：根据你项目的时间点结合你的学习历程简单介绍。比如研一上学的什么然后做了什么，研二学的什么然后做了什么。一定要简介别说细节，可以简单说效果提升。还有你获得过的国奖啊、校奖、acm啊都要说一下。
2、大体按照相关实习经历==发表过的论文（水准高的）>较水论文>top比赛=项目的顺序进行发问。这个东西就看你对自己项目的理解了，没人能帮得了。
3、手写代码，写不上来大概率gg，不过ai公司问的算法都挺easy。
4、一些你平时用的语法的知识 && 深度学习一些基础知识。（这些可以看牛客的面经，很清楚）

问了nms、极大值抑制、ssd、faster rcnn、实习项目

一面主要问你研究方向->实习->逮住一个点比如目标检测直接问到底（手写nms）。面试官很nice，文艺范。
二面直接刚了几个算法。。。回溯之类的（比网上见到头条面试要良心不少）。后面问了几个操作系统相关的知识。

商汤
面了很多c++和c（非科班怕是直接凉，也可能因为本人没论文。）。

1、微积分
1、SGD,Momentum,Adagard,Adam原理

2、L1不可导的时候该怎么办

3、sigmoid函数特性

作者：牛妹
链接：https://www.nowcoder.com/discuss/165930
来源：牛客网

2、统计学，概率论
a,b~U[0,1]，互相独立,求Max(a,b)期望
2、一个活动,n个女生手里拿着长短不一的玫瑰花,无序的排成一排,一个男生从头走到尾,试图拿更长的玫瑰花,一旦拿了一朵就不能再拿其他的,错过了就不能回头,问最好的策略?

3、问题：某大公司有这么一个规定：只要有一个员工过生日，当天所有员工全部放假一天。但在其余时候，所有员工都没有假期，必须正常上班。这个公司需要雇用多少员工，才能让公司一年内所有员工的总工作时间期望值最大？

4、切比雪夫不等式

5、一根绳子,随机截成3段,可以组成一个三角形的概率有多大

6、最大似然估计和最大后验概率的区别?

7、什么是共轭先验分布

8、概率和似然的区别

9.频率学派和贝叶斯学派的区别

10、0~1均匀分布的随机器如何变化成均值为0，方差为1的随机器

11、Lasso的损失函数

12、Sfit特征提取和匹配的具体步骤

作者：牛妹
链接：https://www.nowcoder.com/discuss/165930
来源：牛客网

3、线性代数
1、求mk矩阵A和nk矩阵的欧几里得距离?

2、PCA中第一主成分是第一的原因?

3、欧拉公式

4、矩阵正定性的判断,Hessian矩阵正定性在梯度下降中的应用

5、概率题：抽蓝球红球，蓝结束红放回继续，平均结束游戏抽取次数

6、讲一下PCA

7、拟牛顿法的原理

8、编辑距离

作者：牛妹
链接：https://www.nowcoder.com/discuss/165930
来源：牛客网

1、处理分类问题常用算法
1、交叉熵公式

2、LR公式

3 LR的推导，损失函数

4、逻辑回归怎么实现多分类

5 、SVM中什么时候用线性核什么时候用高斯核?

6、什么是支持向量机,SVM与LR的区别?

7.监督学习和无监督学习的区别

8.机器学习中的距离计算方法?

9、问题：朴素贝叶斯（naive Bayes）法的要求是？

10、问题：训练集中类别不均衡，哪个参数最不准确？

11、问题：你用的模型，最有挑战性的项目

12、问题：SVM的作用，基本实现原理；

13、问题：SVM的硬间隔，软间隔表达式；

14、问题：SVM使用对偶计算的目的是什么，如何推出来的，手写推导；

15、问题：SVM的物理意义是什么；

16、问题：如果给你一些数据集，你会如何分类（我是分情况答的，从数据的大小，特征，是否有缺失，分情况分别答的）；

17、问题： 如果数据有问题，怎么处理；

18、分层抽样的适用范围

19、LR的损失函数

20、LR和线性回归的区别

21 生成模型和判别模型基本形式，有哪些？

22 核函数的种类和应用场景。

23 分类算法列一下有多少种？应用场景。

24、给你一个检测的项目，检测罐装的可口可乐，瓶装的可口可乐作为负样本，怎么弄？

25.SVM核函数的选择

26.SVM的损失函数

27.核函数的作用

28.SVM为什么使用对偶函数求解

29.ID3,C4.5和CART三种决策树的区别

30.SVM和全部数据有关还是和局部数据有关?

31为什么高斯核能够拟合无穷维度

32、第二面完整推导了svm一遍，还有强化学习问的很多，dqn的各种trick了解多少，怎么实现知不知道。

33、SVM所有核函数的了解应用，SVM的损失函数

34、LR和SVM 区别

35、朴素贝叶斯基本原理和预测过程

36、LR推导

37、交叉熵，还有个什么熵不记得了。。。

38、LR公式

39、交叉熵公式

作者：牛妹
链接：https://www.nowcoder.com/discuss/165930
来源：牛客网

2、处理回归问题常用算法
1.L1和L2正则化的区别

2、问题：Loss Function有哪些，怎么用？

3、问题：线性回归的表达式，损失函数；

4、线性回归的损失函数

5、机器学习：知道哪些传统机器学习模型

作者：牛妹
链接：https://www.nowcoder.com/discuss/165930
来源：牛客网

3、处理聚类问题常用算法
1、什么是DBSCAN

2.k-means算法流程

3、LDA的原理

4、介绍几种机器学习的算法，我就结合我的项目经理介绍了些RF, Kmeans等算法。
5、KMeans讲讲，KMeans有什么缺点，K怎么确定
6、Kmeans
7、DBSCAN原理和算法伪代码，与kmeans，OPTICS区别

作者：牛妹
链接：https://www.nowcoder.com/discuss/165930
来源：牛客网

5、模型融合和提升的算法
1 bagging和boosting的区别

2、boosting和 bagging区别

3 XGBOOST和GDBT的区别

4.GDBT的原理,以及常用的调参参数

6、AdaBoost和GBDT的区别,AdaBoost和GBDT的区别

7 gbdt推导
8、boosting和bagging在不同情况下的选用
9、gbdt推导和适用场景
10、说一下gbdt的全部算法过程
11、rf和gbdt基分类器区别，里面的决策树分别长啥样，怎么剪枝
12、随机森林和 GBDT 的区别

13、xgboost的特征重要性计算

14 xgboost的正则项表达式

15 xgboost原理，怎么防过拟合
16、xgboost，rf，lr优缺点场景。。。
17、xgboost特征并行化怎么做的

18、 xgboost和lightgbm的区别和适用场景

6、其他重要算法
1、问题：HMM隐马尔可夫模型的参数估计方法是？

2、问题：Bootstrap方法是什么？

3、问题：如何防止过拟合？

4、 EM算法推导，jensen不等式确定的下界

作者：牛妹
链接：https://www.nowcoder.com/discuss/165930
来源：牛客网

1、Scikit-learn
1、Focal Loss 介绍一下

2 过拟合的解决方法

3 方差偏差的分解公式

4、问题：对应时间序列的数据集如何进行交叉验证？

5、问题：正负样本不平衡的解决办法？评价指标的参考价值？

6、迁移学习

7、数据不平衡怎么办?

8、AUC的理解

9、AUC的计算公式

10、生成模型和判别模型的区别

11、过拟合的解决方法

12、特征选择怎么做

13、怎么防止过拟合

14、L1和L2正则

15、ID3树用什么指标选择特征

16、特征工程的问题

17、给了个链接线上写代码，要求写读文本、文本预处理、特征提取和建模的基本过程，不过写到特征就没写了

18、softmax公式

19、softmax公式

2、Libsvm
1、 检测20类物体，多少张训练集，怎么训练

2、 lightgbm优势

作者：牛妹
链接：https://www.nowcoder.com/discuss/165930
来源：牛客网

四、深度学习
1 BatchNormalization的作用

2、梯度消失

3、循环神经网络，为什么好?

4 什么是GroupConvolution

5.什么是RNN

6.训练过程中,若一个模型不收敛,那么是否说明这个模型无效?导致模型不收敛的原因有哪些?

7.图像处理中锐化和平滑的操作

8.VGG使用3*3卷积核的优势是什么?

9.Relu比Sigmoid的效果好在哪里?

10、问题：神经网络中权重共享的是？

11、问题：神经网络激活函数？

12、问题：在深度学习中，通常会finetuning已有的成熟模型，再基于新数据，修改最后几层神经网络权值，为什么？

13、问题：画GRU结构图

14、Attention机制的作用

15、Lstm和Gru的原理

16、什么是dropout

17、LSTM每个门的计算公式

18、HOG算法原理

19、DropConnect的原理

20 深度学习了解多少，有看过底层代码吗？caffe,tf?

21、除了GMM-HMM，你了解深度学习在语音识别中的应用吗？

22、用过哪些移动端深度学习框架？

作者：牛妹
链接：https://www.nowcoder.com/discuss/165930
来源：牛客网

18、HOG算子是怎么求梯度的

1、BN层的作用，为什么要在后面加伽马和贝塔，不加可以吗

2、梯度消失，梯度爆炸的问题，

3、Adam

4、attention机制

5、RNN梯度消失问题,为什么LSTM和GRU可以解决此问题

6、GAN网络的思想

7、1*1的卷积作用

8、怎么提升网络的泛化能力

9、什么是seq2seq model

10、激活函数的作用

11、为什么用relu就不用sigmoid了

12、讲一下基于WFST的静态解码网络的语音识别流程？

13、目标检测了解吗，Faster RCNN跟RCNN有什么区别

14、SPP，YOLO了解吗？

15、梯度消失梯度爆炸怎么解决

16、RNN容易梯度消失，怎么解决？

17、LSTM跟RNN有啥区别

18、卷积层和池化层有什么区别

19、 防止过拟合有哪些方法

20、dropout咋回事讲讲

21、relu

22、神经网络为啥用交叉熵。

23、注意力公式

24、论文flow情况

25、Flappy.Bird开发者,怎么利用DNQ方法强化学习你的游戏AI

26、LeNet-5结构

27、推导LSTM正向传播和单向传播过程

28、LSTM原理，与GRU区别

29、DNN的梯度更新方式

30、 CNN为什么比DNN在图像识别上更好

31、现场用collabedit写代码，一个怪异的归并算法。。。之前没遇到过，直接把归并写出来，但是说复杂度太高，优化了三遍还不行，最后说出用小顶堆解决了。。。

32、LSTM和Naive RNN的区别

33、神经网络为啥用交叉熵。

34、注意力公式

35、Inception Score 评价指标介绍

36、使用的 CNN 模型权重之间有关联吗？

37、CycleGAN 原理介绍一下

38、训练 GAN 的时候有没有遇到什么问题

39、百度实习：CPM 模型压缩怎么做的？有压过 OpenPose 吗？

40、用过哪些 Optimizer，效果如何

41、图像基础：传统图像处理方法知道哪些，图像对比度增强说一下

42、介绍一下图像的高频、低频部分，知道哪些图像补全的方法

43、百度实习：模型压缩的大方向。CPM 模型怎么压缩的，做了哪些工作？

44、Depthwise 卷积实际速度与理论速度差距较大，解释原因。

45、RetinaNet 的大致结构画一下

46、RetinaNet为什么比SSD效果好

bootstrap数据是什么意思？
有放回地从总共N个样本中抽样n个样本
题目解析：
概念题，bootstrap又称自展法，是用小样本估计总体值的一种非参数方法，基本思想是生成一系列bootstrap伪样本，每个样本是初始数据有放回抽样

下面有关序列模式挖掘算法的描述，错误的是？
https://www.nowcoder.com/questionTerminal/2aefc7fe5f88414997997196089c65c6?orderByHotValue=2&pos=13&mutiTagIds=631